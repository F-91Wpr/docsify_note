### 1. 启动项目需要进程
	zk、kf、maxwell、hdfs、hbase、redis、clickhouse

### 2. 在`/etc/profile.d/my_env.sh`中添加配置

```shell
#FLINK
export HADOOP_CLASSPATH=`hadoop classpath`
```

### 3. 修改`yarn-site.xml`配置  container最小和最大值以及nm分配的内存

```xml
<property>
    <name>yarn.scheduler.minimum-allocation-mb</name>
    <value>1024</value>
</property>
<property>
    <name>yarn.scheduler.maximum-allocation-mb</name>
    <value>2048</value>
</property>
<property>
    <name>yarn.nodemanager.resource.memory-mb</name>
    <value>4096</value>
</property>
```

### 4. 修改 hadoop 下的`capacity-scheduler.xml`配置  

这里意思是集群中可用于运行应用程序主机的最大资源百分比 - 控制并发活动应用程序的数量。每个队列的限制与其队列容量和用户限制成正比。官方文档默认是每个队列最大使用10%的资源，把这里的0.1按需更改最大使用的资源数就行了。

```xml
<property>
    <name>yarn.scheduler.capacity.maximum-am-resource-percent</name>
    <value>1</value>
</property>
```

### 5. 在flink-conf.yaml文件中  添加 `classloader.check-leaked-classloader: false`
	由于hadoop3引入了异步的线程来执行shutdown hook，该hook会在任务执行时运行，由于classloader已经被释放，但是hook中仍然持有该classloader而抛出异常。该异常不影响正常功能，仅在控制台打印日志。
	网上提出一种解决方法：在 flink 配置文件里flink-conf.yaml设置 classloader.check-leaked-classloader: false

### 6. 拷贝资料中flink-shaded-hadoop-2-uber-3.1.3-9.0.jar到flink/lib目录下
	flink对hadoop3的支持

### 7.拷贝`phoenix-5.0.0-HBase-2.0-client.jar`到flink/lib目录下
	cp /opt/module/phoenix/phoenix-5.0.0-HBase-2.0-client.jar /opt/module/flink-1.13.0/lib/


### 8. 修改实时项目中的pom.xml文件，将程序中flink的blink、三个日志包、以及phoenix的scope
	调整为provided，<scope>provided</scope>

### 9. 打包上传到flink目录下

### 10. 启动运行环境需要进程
	在hadoop202上启动历史服务器 
		mapred --daemon start historyserver
	在hadoop203上启动yarn环境
		start-yarn.sh

### 11. 启动DwdTradeOrderPreProcess、DwdTradeOrderDetail、DwsTradeProvinceOrderWindow
-独立分窗口启动
bin/flink run \
-t yarn-per-job \
-d \
-Djobmanager.memory.process.size=1024mb \
-Dtaskmanager.memory.process.size=2048mb \
-Dtaskmanager.numberOfTaskSlots=4 \
-c org.example.gmall.realtime.app.dwd.db.DwdTradeOrderPreProcess \
/opt/module/flink-1.13.0/gmall0301-realtime-1.0-SNAPSHOT.jar


bin/flink run \
-t yarn-per-job \
-d \
-Djobmanager.memory.process.size=1024mb \
-Dtaskmanager.memory.process.size=2048mb \
-Dtaskmanager.numberOfTaskSlots=4 \
-c org.example.gmall.realtime.app.dwd.db.DwdTradeOrderDetail \
/opt/module/flink-1.13.0/gmall0301-realtime-1.0-SNAPSHOT.jar

bin/flink run \
-t yarn-per-job \
-d \
-Djobmanager.memory.process.size=1024mb \
-Dtaskmanager.memory.process.size=2048mb \
-Dtaskmanager.numberOfTaskSlots=4 \
-c org.example.gmall.realtime.app.dws.DwsTradeProvinceOrderWindow \
/opt/module/flink-1.13.0/gmall0301-realtime-1.0-SNAPSHOT.jar
	
-编写realtime.sh脚本
```shell
echo "========DwdTradeOrderPreProcess==============="
bin/flink run \
-t yarn-per-job \
-d \
-Djobmanager.memory.process.size=1024mb \
-Dtaskmanager.memory.process.size=2048mb \
-Dtaskmanager.numberOfTaskSlots=4 \
-c org.example.gmall.realtime.app.dwd.db.DwdTradeOrderPreProcess \
/opt/module/flink-1.13.0/gmall0301-realtime-1.0-SNAPSHOT.jar


echo "========DwdTradeOrderDetail==============="
bin/flink run \
-t yarn-per-job \
-d \
-Djobmanager.memory.process.size=1024mb \
-Dtaskmanager.memory.process.size=2048mb \
-Dtaskmanager.numberOfTaskSlots=4 \
-c org.example.gmall.realtime.app.dwd.db.DwdTradeOrderDetail \
/opt/module/flink-1.13.0/gmall0301-realtime-1.0-SNAPSHOT.jar

echo "========DwsTradeProvinceOrderWindow==============="
bin/flink run \
-t yarn-per-job \
-d \
-Djobmanager.memory.process.size=1024mb \
-Dtaskmanager.memory.process.size=2048mb \
-Dtaskmanager.numberOfTaskSlots=4 \
-c org.example.gmall.realtime.app.dws.DwsTradeProvinceOrderWindow \
/opt/module/flink-1.13.0/gmall0301-realtime-1.0-SNAPSHOT.jar
```
12.打包publisher并上传运行
	
13.修改内网穿透natapp映射的地址
	改为hadoop102:8070	

14.sugar修改空间映射

15.运行模拟生成日志的jar包，查看效果


16.常见问题排查
	-接口服务端口冲突
		查看日志，端口冲突  lsof -i:8070 

	-集群不能启动
		*java.lang.RuntimeException: hbase-default.xml file seems to be for an older version of HBase (null), this version is 2.0.0  
		或者
		Caused by: java.lang.ClassCastException: org.codehaus.janino.CompilerFactory cannot be cast to org.codehaus.commons.compiler.ICompilerFactory
		
		原因:
			和官方jar包冲突
			
		解决：
			将程序中flink的blink、三个日志包、以及phoenix的scope调整为provided，<scope>provided</scope>
			需要将phoenix-5.0.0-HBase-2.0-client.jar到flink/lib目录下
			
	 -Exception in thread “Thread-6” java.lang.IllegalStateException: Trying to access closed classloader. Please check if you store classloaders directly or indirectly in static fields. If the stacktrace suggests that the leak occurs in a third party library and cannot be fixed immediately, you can disable this check with the configuration ‘classloader.check-leaked-classloader’.
	    原因：这是一个hadoop3和flink导致的一个bug  https://issues.apache.org/jira/browse/FLINK-19916

	    解决办法： 在 flink 配置文件里 flink-conf.yaml设置
			classloader.check-leaked-classloader: false

    - springboot打包错误：Failed to execute goal org.apache.maven.plugins:maven-resources-plugin
        原因是打包版本不兼容，可以通过加入如下插件修改版本解决
        <plugin>
            <groupId>org.apache.maven.plugins</groupId>
            <artifactId>maven-resources-plugin</artifactId>
            <version>2.4.3</version>
        </plugin>
