本地安装

<!-- @import "[TOC]" {cmd="toc" depthFrom=1 depthTo=6 orderedList=false} -->

<!-- code_chunk_output -->

- [环境准备](#环境准备)
  - [1. 版本选择](#1-版本选择)
  - [2. 关闭防火墙](#2-关闭防火墙)
  - [3. 取消系统文件数限制](#3-取消系统文件数限制)
  - [4. 安装依赖](#4-安装依赖)
  - [5. 关闭 SELINUX](#5-关闭-selinux)
- [单机安装](#单机安装)
  - [1. 安装包准备](#1-安装包准备)
  - [2. 安装命令](#2-安装命令)
  - [3. 修改配置文件](#3-修改配置文件)
  - [4. 启动](#4-启动)
- [集群部署](#集群部署)
  - [1. 副本](#1-副本)
  - [2. 分片](#2-分片)

<!-- /code_chunk_output -->


## 环境准备

### 1. 版本选择

CentOS: `CentOS Linux release 7.5.1804 (Core)`
ClinkHouse: `20.4.5.36-2`

### 2. 关闭防火墙

```shell
systemctl disable firewalld     --永久关闭
systemctl stop firewalld        --临时关闭
systemctl start firewalld       --开启命令
systemctl status firewalld      --查看状态
```

### 3. 取消系统文件数限制

1. 在hadoop202的 /etc/security/limits.conf文件的末尾加入以下内容

    ```shell
    sudo vim /etc/security/limits.conf
    ```

    ```shell
    * soft nofile 65536 
    * hard nofile 65536 
    * soft nproc 131072 
    * hard nproc 131072
    ```

2. 在hadoop202的/etc/security/limits.d/20-nproc.conf文件的末尾加入以下内容

    ```shell
    sudo vim /etc/security/limits.d/20-nproc.conf
    ```

    ```shell
    * soft nofile 65536 
    * hard nofile 65536 
    * soft nproc 131072 
    * hard nproc 131072
    ```

3. 同步到各节点

### 4. 安装依赖

```shell
sudo yum install -y libtool
sudo yum install -y *unixODBC*
```

### 5. 关闭 SELINUX

```shell
sudo vim /etc/selinux/config
```

```shell
# 修改
SELINUX=disabled
```

## 单机安装

### 1. 安装包准备

下载地址：https://repo.clickhouse.tech/rpm/stable/x86_64/

```text
clickhouse-client-20.4.5.36-2.noarch.rpm
clickhouse-common-static-20.4.5.36-2.x86_64.rpm
clickhouse-common-static-dbg-20.4.5.36-2.x86_64.rpm
clickhouse-server-20.4.5.36-2.noarch.rpm
```

### 2. 安装命令

```shell
sudo rpm -ivh *.rpm
```

查看安装情况
```shell
sudo rpm -qa|grep clickhouse
```

### 3. 修改配置文件

```shell
sudo vim /etc/clickhouse-server/config.xml
```

```shell
# 打开注释
<listen_host>::</listen_host>
```

默认路径：
日志文件路径：`<log>/var/log/clickhouse-server/clickhouse-server.log</log>`
数据文件路径：`<path>/var/lib/clickhouse/</path>`

* 服务器配置文件位于`/etc/clickhouse-server/`。建议重写配置元素的方法是在配置中创建`config.d`文件夹，作为`config.xml`的重写方式。
  
    ```shell
    sudo vim /etc/clickhouse-server/config.xml
    ```

    ```xml
    <!-- By default, path to file with substitutions is /etc/metrika.xml. It could be changed in config in 'include_from' element. -->
    <include_from>/etc/clickhouse-server/config.d/metrika.xml</include_from>
    ```
### 4. 启动

```shell
sudo systemctl start clickhouse-server
sudo systemctl status clickhouse-server

# 启动 client
clickhouse-client -m
```

## 集群部署
https://clickhouse.com/docs/zh/getting-started/tutorial#cluster-deployment

```shell
sudo vim /etc/clickhouse-server/config.d/metrika.xml
```

### 1. 副本

1. Zookeeper 集群设置样例：

    ```xml
    <zookeeper>
        <node index="1">
            <host>hadoop102</host>
            <port>2181</port>
        </node>
        <node index="2">
            <host>hadoop103</host>
            <port>2181</port>
        </node>
        <node index="3">
            <host>hadoop104</host>
            <port>2181</port>
        </node>
    </zookeeper>
    ```

2. 创建复制表

    在表引擎名称上加上 `Replicated` 前缀。例如：`ReplicatedMergeTree`。

    Replicated*MergeTree 参数：

    - `zoo_path` — ZooKeeper 中该表的路径。
    - `replica_name` — ZooKeeper 中的该表的副本名称。
    - `other_parameters` — 关于引擎的一系列参数，这个引擎即是用来创建复制的引擎，例如，`ReplacingMergeTree` 。

    示例:

    ```SQL
    CREATE TABLE table_name
    (
        EventDate DateTime,
        CounterID UInt32,
        UserID UInt32
    ) ENGINE = ReplicatedMergeTree('/clickhouse/tables/{layer}-{shard}/table_name', '{replica}')
    PARTITION BY toYYYYMM(EventDate)
    ORDER BY (CounterID, EventDate, intHash32(UserID))
    ```

    如上例所示，这些参数可以包含宏替换的占位符，即大括号的部分。它们会被替换为配置文件里 `macros` 那部分配置的值。示例：

    ```xml
    <macros>
        <layer>05</layer>
        <shard>02</shard>
        <replica>rep05-02-1</replica>
    </macros>
    ```

    <details>
    <summary>ZooKeeper 中该表的路径对每个可复制表都要是唯一的。不同分片上的表要有不同的路径。</summary>

    `/clickhouse/tables/`是公共前缀，我们推荐使用这个。

    `{layer}-{shard}`是分片标识部分。在此示例中，由于 Yandex.Metrica 集群使用了两级分片，所以它是由两部分组成的。但对于大多数情况来说，你只需保留 {shard} 占位符即可，它会替换展开为分片标识。

    `table_name`是该表在 ZooKeeper 中的名称。使其与 ClickHouse 中的表名相同比较好。 这里它被明确定义，跟 ClickHouse 表名不一样，它并不会被 RENAME 语句修改。 HINT：你也可以在 table_name 前面添加一个数据库名称。例如： db_name.table_name 。

    两个内置的占位符 {database} 和 {table} 也可使用，它们可以展开成数据表名称和数据库名称（只有当这些宏指令在 macros 部分已经定义时才可以）。因此 ZooKeeper 路径可以指定为 `/clickhouse/tables/{layer}-{shard}/{database}/{table}` 。

    当使用这些内置占位符时，请当心数据表重命名。 ZooKeeper 中的路径无法变更，而当数据表被重命名时，宏命令将展开为另一个路径，数据表将指向一个 ZooKeeper 上并不存在的路径，并因此转变为只读模式。
    </details>

### 2. 分片

```shell
vim /etc/clickhouse-server/config.d/metrika-shard.xml
```

1. 集群

    ```xml
    <remote_servers>
        <logs>
            <!-- 分布式查询的服务器间集群密码
                默认值:无密码(将不执行身份验证)

                如果设置了，那么分布式查询将在分片上验证，所以至少:
                - 这样的集群应该存在于shard上
                - 这样的集群应该有相同的密码。

                而且(这是更重要的)，initial_user将作为查询的当前用户使用。
            -->
            <!-- <secret></secret> -->
            <shard>
                <!-- 可选的。写数据时分片权重。 默认: 1. -->
                <weight>1</weight>
                <!-- 可选的。是否只将数据写入其中一个副本。默认值:false(将数据写入所有副本)。 -->
                <internal_replication>false</internal_replication>
                <replica>
                    <!-- 可选的。负载均衡副本的优先级，请参见（load_balancing 设置)。默认值:1(值越小优先级越高)。 -->
                    <priority>1</priority>
                    <host>example01-01-1</host>
                    <port>9000</port>
                </replica>
                <replica>
                    <host>example01-01-2</host>
                    <port>9000</port>
                </replica>
            </shard>
            <shard>
                <weight>2</weight>
                <internal_replication>false</internal_replication>
                <replica>
                    <host>example01-02-1</host>
                    <port>9000</port>
                </replica>
                <replica>
                    <host>example01-02-2</host>
                    <secure>1</secure>
                    <port>9440</port>
                </replica>
            </shard>
        </logs>
    </remote_servers>
    ```

    <details>
    <summary>参数</summary>
    这里定义了一个名为’logs’的集群，它由两个分片组成，每个分片包含两个副本。 分片是指包含数据不同部分的服务器（要读取所有数据，必须访问所有分片）。 副本是存储复制数据的服务器（要读取所有数据，访问任一副本上的数据即可）。

    集群名称不能包含点号。

    每个服务器需要指定 host，port，和可选的 user，password，secure，compression 的参数：

    - host – 远程服务器地址。可以域名、IPv4或IPv6。如果指定域名，则服务在启动时发起一个 DNS 请求，并且请求结果会在服务器运行期间一直被记录。如果 DNS 请求失败，则服务不会启动。如果你修改了 DNS 记录，则需要重启服务。
    - port – 消息传递的 TCP 端口（「tcp_port」配置通常设为 9000）。不要跟 http_port 混淆。
    - user – 用于连接远程服务器的用户名。默认值：default。该用户必须有权限访问该远程服务器。访问权限配置在 users.xml 文件中。
    - password – 用于连接远程服务器的密码。默认值：空字符串。
    - secure – 是否使用ssl进行连接，设为true时，通常也应该设置 port = 9440。服务器也要监听 <tcp_port_secure>9440</tcp_port_secure> 并有正确的证书。
    - compression - 是否使用数据压缩。默认值：true。
  
    配置了副本，读取操作会从每个分片里选择一个可用的副本。可配置负载平衡算法（挑选副本的方式） - 请参阅«load_balancing»设置。 如果跟服务器的连接不可用，则在尝试短超时的重连。如果重连失败，则选择下一个副本，依此类推。如果跟所有副本的连接尝试都失败，则尝试用相同的方式再重复几次。 该机制有利于系统可用性，但不保证完全容错：如有远程服务器能够接受连接，但无法正常工作或状况不佳。

    你可以配置一个（这种情况下，查询操作更应该称为远程查询，而不是分布式查询）或任意多个分片。在每个分片中，可以配置一个或任意多个副本。不同分片可配置不同数量的副本。

    可以在配置中配置任意数量的集群。
    </details>

2. 创建数据表

    ```SQL
    CREATE TABLE [IF NOT EXISTS] [db.]table_name [ON CLUSTER cluster]
    (
        name1 [type1] [DEFAULT|MATERIALIZED|ALIAS expr1],
        name2 [type2] [DEFAULT|MATERIALIZED|ALIAS expr2],
        ...
    ) ENGINE = Distributed(cluster, database, table[, sharding_key[, policy_name]])
    [SETTINGS name=value, ...]
    ```

    <details>
    <summary>分布式引擎参数</summary>

    - `cluster` - 服务为配置中的集群名

    - `database` - 远程数据库名

    - `table` - 远程数据表名

    - `sharding_key` - (可选) 分片key,分片键必须是整型数字，所以用hiveHash函数转换，也可以rand()

    - `policy_name` - (可选) 规则名，它会被用作存储临时文件以便异步发送数据
    </details>

    <details>
    <summary>分布式设置</summary>

    - `fsync_after_insert` - 对异步插入到分布式的文件数据执行fsync。确保操作系统将所有插入的数据刷新到启动节点磁盘上的一个文件中。

    - `fsync_directories` - 对目录执行fsync。保证操作系统在分布式表上进行异步插入相关操作(插入后，发送数据到分片等)后刷新目录元数据.

    - `bytes_to_throw_insert` - 如果超过这个数量的压缩字节将等待异步INSERT，将抛出一个异常。0 - 不抛出。默认值0.

    - `bytes_to_delay_insert` - 如果超过这个数量的压缩字节将等待异步INSERT，查询将被延迟。0 - 不要延迟。默认值0.

    - `max_delay_to_insert` - 最大延迟多少秒插入数据到分布式表，如果有很多挂起字节异步发送。默认值60。

    - `monitor_batch_inserts` - 等同于 distributed_directory_monitor_batch_inserts

    - `monitor_split_batch_on_failure` - 等同于distributed_directory_monitor_split_batch_on_failure

    - `monitor_sleep_time_ms` - 等同于 distributed_directory_monitor_sleep_time_ms

    - `monitor_max_sleep_time_ms` - 等同于 distributed_directory_monitor_max_sleep_time_ms
    </details>